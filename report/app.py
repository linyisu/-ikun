import streamlit as st
import pandas as pd
import os
import csv
import time
import json
import hashlib
import urllib
import re
import requests
from datetime import datetime
from dotenv import load_dotenv
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import jieba

st.markdown(
    """
    <style>
    .block-container {
        max-width: 55%;
        margin: 0 auto;
    }
    [data-testid="stImageContainer"] {
        display: flex;
        justify-content: center;
    }
    [data-testid="stImageContainer"] img {
        width: 65% !important;
        height: auto !important;
        border-radius: 16px;
        box-shadow: 0 4px 10px rgba(0,0,0,0.15);
        display: block;
        margin-left: auto;
        margin-right: auto;
    }

    </style>
    """,
    unsafe_allow_html=True
)

# ========== å·¥å…·å‡½æ•° ==========
def get_Header():
    cookie = os.getenv('BILI_COOKIE')
    header = {
        "Cookie": cookie,
        "User-Agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36'
    }
    return header

def get_avid_from_bv(bv):
    url = f'https://api.bilibili.com/x/web-interface/view?bvid={bv}'
    response = requests.get(url, headers=get_Header())
    data = response.json()
    if data.get('code', 0) != 0:
        raise Exception(f"è·å–avidå¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
    return data['data']['aid']

def md5(code):
    return hashlib.md5(code.encode('utf-8')).hexdigest()

def fetch_comments(bv, is_second=True, max_pages=1000):
    aid = get_avid_from_bv(bv)
    pagination_str = ''
    count = 0
    comments = []

    for page in range(max_pages):
        wts = int(time.time())
        offset = f'"offset":"{pagination_str}"' if pagination_str else '"offset":""'
        payload = f"mode=2&oid={aid}&pagination_str=%7B{offset}%7D&plat=1&type=1&web_location=1315875&wts={wts}"
        w_rid = md5(payload + 'ea1db124af3c7062474693fa704f4ff8')
        url = f"https://api.bilibili.com/x/v2/reply/wbi/main?oid={aid}&type=1&mode=2&pagination_str=%7B{offset}%7D&plat=1&web_location=1315875&w_rid={w_rid}&wts={wts}"

        res = requests.get(url, headers=get_Header()).json()
        replies = res.get("data", {}).get("replies", [])
        if not replies:
            break

        for r in replies:
            count += 1
            comments.append({
                "ç”¨æˆ·å": r["member"]["uname"],
                "è¯„è®ºå†…å®¹": r["content"]["message"],
                "ç‚¹èµæ•°": r["like"],
                "è¯„è®ºæ—¶é—´": datetime.fromtimestamp(r["ctime"]).strftime('%Y-%m-%d %H:%M:%S'),
            })

        pagination_str = res['data']['cursor']['pagination_reply'].get('next_offset', 0)
        if not pagination_str:
            break
        time.sleep(0.5)
    
    return comments

# ========== Streamlit App ==========
def main():
    load_dotenv()
    st.title("ğŸ¥ Bç«™è¯„è®ºçˆ¬å–å™¨")

    bv = st.text_input("è¯·è¾“å…¥BVå·:", "")
    is_click = st.button("å¼€å§‹çˆ¬å–")

    df = None
    file_path = None

    if is_click and bv:
        with st.spinner("æ­£åœ¨çˆ¬å–è¯„è®ºä¸­..."):
            try:
                data = fetch_comments(bv)  # åªçˆ¬18é¡µé˜²æ­¢å¤ªæ…¢
                # cy
                if not data:
                    st.warning("æ²¡æœ‰çˆ¬å–åˆ°ä»»ä½•è¯„è®ºã€‚")
                    return
                df = pd.DataFrame(data)
                st.session_state['df'] = df  # å­˜å…¥session_state
                st.success(f"âœ… çˆ¬å–æˆåŠŸï¼Œå…± {len(df)} æ¡è¯„è®º")
                # åªæ˜¾ç¤ºä¸€æ¬¡è¯„è®ºåŒºå’Œä¸‹è½½æŒ‰é’®
                with st.container():
                    st.dataframe(df, key="comments_df")
                    file_path = f"data/{bv}_comments.csv"
                    df.to_csv(file_path, index=False, encoding="utf-8-sig")
                    st.session_state['file_path'] = file_path  # å­˜å…¥session_state
                    st.download_button("ğŸ“¥ ä¸‹è½½è¯„è®º CSV æ–‡ä»¶", data=df.to_csv(index=False, encoding="utf-8-sig"), file_name=f"{bv}_comments.csv", mime="text/csv", key="download_btn")
            except Exception as e:
                st.error(f"âŒ å‡ºé”™äº†ï¼š{e}")
                import traceback
                st.text(traceback.format_exc())
                return
    # åªåœ¨æœ‰è¯„è®ºæ•°æ®åæ‰æ˜¾ç¤ºåˆ†æè¯äº‘æŒ‰é’®
    if 'df' in st.session_state and st.session_state['df'] is not None:
        # ç”¨st.container()åˆ†ç»„ï¼Œä¿è¯è¯äº‘å’Œè¯„è®ºåŒºå†…å®¹å¹¶å­˜
        with st.container():
            if st.button("åˆ†æè¯äº‘"):
                st.info("æ­£åœ¨ç”Ÿæˆè¯äº‘ï¼Œè¯·ç¨å€™...")
                df = st.session_state.get('df', None)
                file_path = st.session_state.get('file_path', None)
                if df is None and file_path:
                    df = pd.read_csv(file_path)
                if df is None or 'è¯„è®ºå†…å®¹' not in df.columns:
                    st.error("æ²¡æœ‰å¯ç”¨çš„è¯„è®ºå†…å®¹ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    return
                text = ' '.join(df['è¯„è®ºå†…å®¹'].astype(str))
                # åŠ è½½åœç”¨è¯
                stopwords = set()
                try:
                    with open('stopwords.txt', 'r', encoding='utf-8') as f:
                        for line in f:
                            stopwords.add(line.strip())
                except FileNotFoundError:
                    stopwords = set(['çš„', 'äº†', 'å’Œ', 'æ˜¯', 'æˆ‘', 'ä¹Ÿ', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'ç€', 'æˆ–', 'ä¸€ä¸ª', 'æ²¡æœ‰', 'æˆ‘ä»¬', 'ä½ ', 'ä½ ä»¬', 'ä»–', 'å¥¹', 'å®ƒ', 'å•Š', 'å§', 'å—', 'å‘¢'])
                # åˆ†è¯å¹¶å»é™¤åœç”¨è¯å’Œå•å­—
                words = [w for w in jieba.cut(text) if w not in stopwords and len(w) > 1]
                if not words:
                    st.warning("åˆ†è¯åæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    return
                result = ' '.join(words)
                wc = WordCloud(font_path='msyh.ttc', background_color='white', width=800, height=600)
                try:
                    wc.generate(result)
                    st.image(wc.to_array(), caption="è¯„è®ºè¯äº‘", use_container_width=True)
                except Exception as e:
                    st.error(f"è¯äº‘ç”Ÿæˆå¤±è´¥ï¼š{e}")
                    import traceback
                    st.text(traceback.format_exc())

if __name__ == "__main__":
    main()
