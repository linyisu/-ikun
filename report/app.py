import streamlit as st
import pandas as pd
import os
import time
import hashlib
import requests
from datetime import datetime
from dotenv import load_dotenv
from wordcloud import WordCloud
import jieba
from streamlit_echarts import st_echarts
from collections import Counter

# ========== é¡µé¢æ ·å¼ç¾åŒ– ==========
st.markdown(
    """
    <style>
    .block-container {
        max-width: 55%;
        margin: 0 auto;
    }
    [data-testid="stImageContainer"] {
        display: flex;
        justify-content: center;
    }
    [data-testid="stImageContainer"] img {
        width: 65% !important;
        height: auto !important;
        border-radius: 16px;
        box-shadow: 0 4px 10px rgba(0,0,0,0.15);
        display: block;
        margin-left: auto;
        margin-right: auto;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ========== å·¥å…·å‡½æ•° ==========
def get_Header():
    """è·å–Bç«™è¯·æ±‚å¤´ï¼Œéœ€é…ç½®BILI_COOKIEç¯å¢ƒå˜é‡"""
    cookie = os.getenv('BILI_COOKIE')
    header = {
        "Cookie": cookie,
        "User-Agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36'
    }
    return header

def get_avid_from_bv(bv):
    """é€šè¿‡BVå·è·å–avid"""
    url = f'https://api.bilibili.com/x/web-interface/view?bvid={bv}'
    response = requests.get(url, headers=get_Header())
    data = response.json()
    if data.get('code', 0) != 0:
        raise Exception(f"è·å–avidå¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
    return data['data']['aid']

def md5(code):
    """ç”ŸæˆMD5æ‘˜è¦"""
    return hashlib.md5(code.encode('utf-8')).hexdigest()

def fetch_comments(bv, max_pages=1000):
    """çˆ¬å–Bç«™è¯„è®ºï¼Œè¿”å›è¯„è®ºåˆ—è¡¨"""
    aid = get_avid_from_bv(bv)
    pagination_str = ''
    comments = []
    for page in range(max_pages):
        wts = int(time.time())
        offset = f'"offset":"{pagination_str}"' if pagination_str else '"offset":""'
        payload = f"mode=2&oid={aid}&pagination_str=%7B{offset}%7D&plat=1&type=1&web_location=1315875&wts={wts}"
        w_rid = md5(payload + 'ea1db124af3c7062474693fa704f4ff8')
        url = f"https://api.bilibili.com/x/v2/reply/wbi/main?oid={aid}&type=1&mode=2&pagination_str=%7B{offset}%7D&plat=1&web_location=1315875&w_rid={w_rid}&wts={wts}"
        res = requests.get(url, headers=get_Header()).json()
        replies = res.get("data", {}).get("replies", [])
        if not replies:
            break
        for r in replies:
            comments.append({
                "ç”¨æˆ·å": r["member"]["uname"],
                "è¯„è®ºå†…å®¹": r["content"]["message"],
                "ç‚¹èµæ•°": r["like"],
                "è¯„è®ºæ—¶é—´": datetime.fromtimestamp(r["ctime"]).strftime('%Y-%m-%d %H:%M:%S'),
            })
        pagination_str = res['data']['cursor']['pagination_reply'].get('next_offset', 0)
        if not pagination_str:
            break
        time.sleep(0.5)
    return comments

def load_stopwords():
    """åŠ è½½åœç”¨è¯è¡¨"""
    stopwords = set()
    try:
        with open('stopwords.txt', 'r', encoding='utf-8') as f:
            for line in f:
                stopwords.add(line.strip())
    except FileNotFoundError:
        stopwords = set(['çš„', 'äº†', 'å’Œ', 'æ˜¯', 'æˆ‘', 'ä¹Ÿ', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'ç€', 'æˆ–', 'ä¸€ä¸ª', 'æ²¡æœ‰', 'æˆ‘ä»¬', 'ä½ ', 'ä½ ä»¬', 'ä»–', 'å¥¹', 'å®ƒ', 'å•Š', 'å§', 'å—', 'å‘¢'])
    return stopwords

def generate_wordcloud(text, stopwords):
    """ç”Ÿæˆé™æ€è¯äº‘å›¾ç‰‡"""
    words = [w for w in jieba.cut(text) if w not in stopwords and len(w) > 1]
    if not words:
        return None
    result = ' '.join(words)
    wc = WordCloud(font_path='msyh.ttc', background_color='white', width=800, height=600)
    wc.generate(result)
    return wc.to_array()

def generate_wordcloud_data(text, stopwords):
    """ç”Ÿæˆè¯é¢‘æ•°æ®ç”¨äºäº¤äº’è¯äº‘"""
    words = [w for w in jieba.cut(text) if w not in stopwords and len(w) > 1]
    if not words:
        return []
    word_freq = Counter(words)
    return [{"name": k, "value": v} for k, v in word_freq.most_common(200)]

# ========== Streamlit ä¸»ç•Œé¢ ==========
def main():
    load_dotenv()
    st.title("ğŸ¥ Bç«™è¯„è®ºçˆ¬å–å™¨")

    # ====== 1. çˆ¬å–è¯„è®ºåŒº ======
    bv = st.text_input("è¯·è¾“å…¥BVå·:", "")
    is_click = st.button("å¼€å§‹çˆ¬å–")
    df = None
    file_path = None
    if is_click and bv:
        with st.spinner("æ­£åœ¨çˆ¬å–è¯„è®ºä¸­..."):
            try:
                data = fetch_comments(bv, max_pages=15)
                if not data:
                    st.warning("æ²¡æœ‰çˆ¬å–åˆ°ä»»ä½•è¯„è®ºã€‚")
                    return
                df = pd.DataFrame(data)
                st.session_state['df'] = df
                st.success(f"âœ… çˆ¬å–æˆåŠŸï¼Œå…± {len(df)} æ¡è¯„è®º")
                with st.container():
                    st.dataframe(df, key="comments_df")
                    file_path = f"data/{bv}_comments.csv"
                    df.to_csv(file_path, index=False, encoding="utf-8-sig")
                    st.session_state['file_path'] = file_path
                    st.download_button("ğŸ“¥ ä¸‹è½½è¯„è®º CSV æ–‡ä»¶", data=df.to_csv(index=False, encoding="utf-8-sig"), file_name=f"{bv}_comments.csv", mime="text/csv", key="download_btn")
            except Exception as e:
                st.error(f"âŒ å‡ºé”™äº†ï¼š{e}")
                import traceback
                st.text(traceback.format_exc())
                return

    # ====== 2. è¯„è®ºåˆ†æä¸å¯è§†åŒ–åŒº ======
    if 'df' in st.session_state and st.session_state['df'] is not None:
        df = st.session_state['df']
        stopwords = load_stopwords()
        with st.container():
            # é™æ€è¯äº‘
            if st.button("åˆ†æè¯äº‘ï¼ˆé™æ€å›¾ç‰‡ï¼‰"):
                st.info("æ­£åœ¨ç”Ÿæˆè¯äº‘ï¼Œè¯·ç¨å€™...")
                if 'è¯„è®ºå†…å®¹' not in df.columns:
                    st.error("æ²¡æœ‰å¯ç”¨çš„è¯„è®ºå†…å®¹ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df['è¯„è®ºå†…å®¹'].astype(str))
                    img = generate_wordcloud(text, stopwords)
                    if img is None:
                        st.warning("åˆ†è¯åæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        st.image(img, caption="è¯„è®ºè¯äº‘", use_container_width=True)
            # äº¤äº’è¯äº‘
            if st.button("åˆ†æè¯äº‘ï¼ˆå¯äº¤äº’ï¼‰"):
                if 'è¯„è®ºå†…å®¹' not in df.columns:
                    st.error("æ²¡æœ‰å¯ç”¨çš„è¯„è®ºå†…å®¹ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df['è¯„è®ºå†…å®¹'].astype(str))
                    data = generate_wordcloud_data(text, stopwords)
                    if not data:
                        st.warning("åˆ†è¯åæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        option = {
                            "backgroundColor": "#f5f7fa",
                            "tooltip": {"show": True},
                            "series": [{
                                "type": 'wordCloud',
                                "shape": 'star',
                                "gridSize": 8,
                                "sizeRange": [20, 90],
                                "rotationRange": [-45, 90],
                                "rotationStep": 15,
                                "left": "center",
                                "top": "center",
                                "width": "100%",
                                "height": "100%",
                                "textStyle": {
                                    "fontFamily": "å¾®è½¯é›…é»‘",
                                    "fontWeight": "bold",
                                    "shadowColor": "#b7e3fa",
                                    "shadowBlur": 8,
                                    "color": {
                                        "type": "radial",
                                        "x": 0.5,
                                        "y": 0.5,
                                        "r": 0.8,
                                        "colorStops": [
                                            {"offset": 0, "color": "#91caff"},
                                            {"offset": 0.5, "color": "#f9e79f"},
                                            {"offset": 1, "color": "#ffb3b3"}
                                        ]
                                    }
                                },
                                "emphasis": {
                                    "focus": "self",
                                    "textStyle": {
                                        "shadowBlur": 16,
                                        "shadowColor": "#fff",
                                        "color": "#faad14"
                                    }
                                },
                                "drawOutOfBound": False,
                                "data": data
                            }]
                        }
                        st_echarts(option, height="600px")
        # è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–æ›²çº¿
        st.markdown("---")
        st.subheader("ğŸ“ˆ è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–æ›²çº¿ï¼ˆå¯é€‰åŒºé—´ï¼‰")
        if 'è¯„è®ºæ—¶é—´' in df.columns:
            df['è¯„è®ºæ—¶é—´'] = pd.to_datetime(df['è¯„è®ºæ—¶é—´'])
            min_date = df['è¯„è®ºæ—¶é—´'].min().date()
            max_date = df['è¯„è®ºæ—¶é—´'].max().date()
            col1, col2, col3 = st.columns([2,2,2])
            with col1:
                start_date = st.date_input("èµ·å§‹æ—¥æœŸ", min_value=min_date, max_value=max_date, value=min_date, key="start_date")
            with col2:
                end_date = st.date_input("ç»“æŸæ—¥æœŸ", min_value=min_date, max_value=max_date, value=max_date, key="end_date")
            with col3:
                freq = st.radio("èšåˆç²’åº¦", ["æŒ‰å¤©", "æŒ‰å°æ—¶"], horizontal=True, key="agg_freq")
            mask = (df['è¯„è®ºæ—¶é—´'].dt.date >= start_date) & (df['è¯„è®ºæ—¶é—´'].dt.date <= end_date)
            df_filtered = df.loc[mask].copy()
            if df_filtered.empty:
                st.warning("æ‰€é€‰åŒºé—´å†…æ— è¯„è®ºæ•°æ®ï¼")
            else:
                import altair as alt
                if freq == "æŒ‰å¤©":
                    df_filtered['æ—¥æœŸ'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.date
                    count_df = df_filtered.groupby('æ—¥æœŸ').size().reset_index(name='è¯„è®ºæ•°')
                    x = count_df['æ—¥æœŸ'].astype(str)
                else:
                    df_filtered['å°æ—¶'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.strftime('%Y-%m-%d %H:00')
                    count_df = df_filtered.groupby('å°æ—¶').size().reset_index(name='è¯„è®ºæ•°')
                    x = count_df['å°æ—¶']
                chart = alt.Chart(count_df).mark_line(point=True, color="#409EFF").encode(
                    x=alt.X(x.name, title="æ—¶é—´"),
                    y=alt.Y('è¯„è®ºæ•°', title="è¯„è®ºæ•°é‡"),
                    tooltip=[x.name, 'è¯„è®ºæ•°']
                ).properties(
                    width=700,
                    height=350
                ).interactive()
                st.altair_chart(chart, use_container_width=True)
    else:
        st.info("è¯·å…ˆçˆ¬å–è¯„è®ºæ•°æ®ã€‚")

    # ====== 3. å±•ç¤ºæœ¬åœ°CSVåˆ†æåŒº ======
    st.markdown("---")
    st.subheader("ğŸ“‚ æˆ–ç›´æ¥å±•ç¤ºæœ¬åœ° comments.csv æ•°æ®")
    if st.button("å±•ç¤ºCSVå›¾è¡¨", key="show_csv_btn"):
        csv_path = "comments.csv"
        if not os.path.exists(csv_path):
            st.error("å½“å‰ç›®å½•ä¸‹æœªæ‰¾åˆ° comments.csv æ–‡ä»¶ï¼")
        else:
            df_csv = pd.read_csv(csv_path)
            st.success(f"å·²åŠ è½½ comments.csvï¼Œå…± {len(df_csv)} æ¡è¯„è®º")
            st.dataframe(df_csv)
            # è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–æ›²çº¿
            if 'è¯„è®ºæ—¶é—´' in df_csv.columns:
                df_csv['è¯„è®ºæ—¶é—´'] = pd.to_datetime(df_csv['è¯„è®ºæ—¶é—´'], errors='coerce')
                min_date = df_csv['è¯„è®ºæ—¶é—´'].min().date()
                max_date = df_csv['è¯„è®ºæ—¶é—´'].max().date()
                col1, col2, col3 = st.columns([2,2,2])
                with col1:
                    start_date = st.date_input("èµ·å§‹æ—¥æœŸ", min_value=min_date, max_value=max_date, value=min_date, key="csv_start_date")
                with col2:
                    end_date = st.date_input("ç»“æŸæ—¥æœŸ", min_value=min_date, max_value=max_date, value=max_date, key="csv_end_date")
                with col3:
                    freq = st.radio("èšåˆç²’åº¦", ["æŒ‰å¤©", "æŒ‰æ˜ŸæœŸ"], horizontal=True, key="csv_agg_freq")
                mask = (df_csv['è¯„è®ºæ—¶é—´'].dt.date >= start_date) & (df_csv['è¯„è®ºæ—¶é—´'].dt.date <= end_date)
                df_filtered = df_csv.loc[mask].copy()
                if df_filtered.empty:
                    st.warning("æ‰€é€‰åŒºé—´å†…æ— è¯„è®ºæ•°æ®ï¼")
                else:
                    import altair as alt
                    if freq == "æŒ‰å¤©":
                        df_filtered['æ—¥æœŸ'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.date
                        count_df = df_filtered.groupby('æ—¥æœŸ').size().reset_index(name='è¯„è®ºæ•°')
                        x = count_df['æ—¥æœŸ'].astype(str)
                    else:  # æŒ‰æ˜ŸæœŸ
                        df_filtered['æ˜ŸæœŸ'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.dayofweek
                        week_map = {0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'}
                        df_filtered['æ˜ŸæœŸ'] = df_filtered['æ˜ŸæœŸ'].map(week_map)
                        count_df = df_filtered.groupby('æ˜ŸæœŸ').size().reindex(['å‘¨ä¸€','å‘¨äºŒ','å‘¨ä¸‰','å‘¨å››','å‘¨äº”','å‘¨å…­','å‘¨æ—¥']).reset_index(name='è¯„è®ºæ•°').fillna(0)
                        x = count_df['æ˜ŸæœŸ']
                    chart = alt.Chart(count_df).mark_line(point=True, color="#13c2c2").encode(
                        x=alt.X(x.name, title="æ—¶é—´"),
                        y=alt.Y('è¯„è®ºæ•°', title="è¯„è®ºæ•°é‡"),
                        tooltip=[x.name, 'è¯„è®ºæ•°']
                    ).properties(
                        width=700,
                        height=350
                    ).interactive()
                    st.altair_chart(chart, use_container_width=True)
            # è¯äº‘ï¼ˆé™æ€/äº¤äº’ï¼‰
            if st.button("ç”Ÿæˆè¯äº‘ï¼ˆé™æ€ï¼‰", key="csv_wc_static"):
                if 'è¯„è®ºå†…å®¹' not in df_csv.columns:
                    st.error("CSVä¸­æ— è¯„è®ºå†…å®¹å­—æ®µï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df_csv['è¯„è®ºå†…å®¹'].astype(str))
                    stopwords = load_stopwords()
                    img = generate_wordcloud(text, stopwords)
                    if img is None:
                        st.warning("åˆ†è¯åæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        st.image(img, caption="è¯„è®ºè¯äº‘", use_container_width=True)
            if st.button("ç”Ÿæˆè¯äº‘ï¼ˆäº¤äº’ï¼‰", key="csv_wc_echarts"):
                if 'è¯„è®ºå†…å®¹' not in df_csv.columns:
                    st.error("CSVä¸­æ— è¯„è®ºå†…å®¹å­—æ®µï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df_csv['è¯„è®ºå†…å®¹'].astype(str))
                    stopwords = load_stopwords()
                    data = generate_wordcloud_data(text, stopwords)
                    if not data:
                        st.warning("åˆ†è¯åæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        option = {
                            "backgroundColor": "#f5f7fa",
                            "tooltip": {"show": True},
                            "series": [{
                                "type": 'wordCloud',
                                "shape": 'star',
                                "gridSize": 8,
                                "sizeRange": [20, 90],
                                "rotationRange": [-45, 90],
                                "rotationStep": 15,
                                "left": "center",
                                "top": "center",
                                "width": "100%",
                                "height": "100%",
                                "textStyle": {
                                    "fontFamily": "å¾®è½¯é›…é»‘",
                                    "fontWeight": "bold",
                                    "shadowColor": "#b7e3fa",
                                    "shadowBlur": 8,
                                    "color": {
                                        "type": "radial",
                                        "x": 0.5,
                                        "y": 0.5,
                                        "r": 0.8,
                                        "colorStops": [
                                            {"offset": 0, "color": "#91caff"},
                                            {"offset": 0.5, "color": "#f9e79f"},
                                            {"offset": 1, "color": "#ffb3b3"}
                                        ]
                                    }
                                },
                                "emphasis": {
                                    "focus": "self",
                                    "textStyle": {
                                        "shadowBlur": 16,
                                        "shadowColor": "#fff",
                                        "color": "#faad14"
                                    }
                                },
                                "drawOutOfBound": False,
                                "data": data
                            }]
                        }
                        st_echarts(option, height="600px")

if __name__ == "__main__":
    main()
