"""
é¡µé¢æ¸²æŸ“æ¨¡å—
"""
import streamlit as st
from report.logic import fetch_comments
from analysis.word_cloud import load_stopwords, generate_wordcloud, generate_wordcloud_data
import pandas as pd
import os
from config.settings import DATA_DIR

def render_crawler_section():
    """è¯„è®ºçˆ¬å–åŒºå—"""
    bv = st.text_input("è¯·è¾“å…¥BVå·:", "")
    is_click = st.button("å¼€å§‹çˆ¬å–")
    if is_click and bv:
        with st.spinner("æ­£åœ¨çˆ¬å–è¯„è®ºä¸­..."):
            try:
                data = fetch_comments(bv, max_pages=15)
                if not data:
                    st.warning("æ²¡æœ‰çˆ¬å–åˆ°ä»»ä½•è¯„è®ºã€‚")
                    return
                df = pd.DataFrame(data)
                st.session_state['df'] = df
                st.success(f"âœ… çˆ¬å–æˆåŠŸï¼Œå…± {len(df)} æ¡è¯„è®º")
                with st.container():
                    st.dataframe(df, key="comments_df")
                    file_path = DATA_DIR / f"{bv}_comments.csv"
                    df.to_csv(file_path, index=False, encoding="utf-8-sig")
                    st.session_state['file_path'] = file_path
                    st.download_button("ðŸ“¥ ä¸‹è½½è¯„è®º CSV æ–‡ä»¶", data=df.to_csv(index=False, encoding="utf-8-sig"), file_name=f"{bv}_comments.csv", mime="text/csv", key="download_btn")
            except Exception as e:
                st.error(f"âŒ å‡ºé”™äº†ï¼š{e}")
                import traceback
                st.text(traceback.format_exc())
                return

def render_analysis_section():
    """è¯„è®ºåˆ†æžä¸Žå¯è§†åŒ–åŒºå—"""
    if 'df' in st.session_state and st.session_state['df'] is not None:
        df = st.session_state['df']
        stopwords = load_stopwords()
        with st.container():
            # é™æ€è¯äº‘
            if st.button("åˆ†æžè¯äº‘ï¼ˆé™æ€å›¾ç‰‡ï¼‰"):
                st.info("æ­£åœ¨ç”Ÿæˆè¯äº‘ï¼Œè¯·ç¨å€™...")
                if 'è¯„è®ºå†…å®¹' not in df.columns:
                    st.error("æ²¡æœ‰å¯ç”¨çš„è¯„è®ºå†…å®¹ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df['è¯„è®ºå†…å®¹'].astype(str))
                    img = generate_wordcloud(text, stopwords)
                    if img is None:
                        st.warning("åˆ†è¯åŽæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        st.image(img, caption="è¯„è®ºè¯äº‘", use_container_width=True)
            # äº¤äº’è¯äº‘
            if st.button("åˆ†æžè¯äº‘ï¼ˆå¯äº¤äº’ï¼‰"):
                if 'è¯„è®ºå†…å®¹' not in df.columns:
                    st.error("æ²¡æœ‰å¯ç”¨çš„è¯„è®ºå†…å®¹ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df['è¯„è®ºå†…å®¹'].astype(str))
                    data = generate_wordcloud_data(text, stopwords)
                    if not data:
                        st.warning("åˆ†è¯åŽæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        from streamlit_echarts import st_echarts
                        option = {
                            "backgroundColor": "#f5f7fa",
                            "tooltip": {"show": True},
                            "series": [{
                                "type": 'wordCloud',
                                "shape": 'star',
                                "gridSize": 8,
                                "sizeRange": [20, 90],
                                "rotationRange": [-45, 90],
                                "rotationStep": 15,
                                "left": "center",
                                "top": "center",
                                "width": "100%",
                                "height": "100%",
                                "textStyle": {
                                    "fontFamily": "å¾®è½¯é›…é»‘",
                                    "fontWeight": "bold",
                                    "shadowColor": "#b7e3fa",
                                    "shadowBlur": 8,
                                    "color": {
                                        "type": "radial",
                                        "x": 0.5,
                                        "y": 0.5,
                                        "r": 0.8,
                                        "colorStops": [
                                            {"offset": 0, "color": "#91caff"},
                                            {"offset": 0.5, "color": "#f9e79f"},
                                            {"offset": 1, "color": "#ffb3b3"}
                                        ]
                                    }
                                },
                                "emphasis": {
                                    "focus": "self",
                                    "textStyle": {
                                        "shadowBlur": 16,
                                        "shadowColor": "#fff",
                                        "color": "#faad14"
                                    }
                                },
                                "drawOutOfBound": False,
                                "data": data
                            }]
                        }
                        st_echarts(option, height="600px")
        # è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–æ›²çº¿
        st.markdown("---")
        st.subheader("ðŸ“ˆ è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–æ›²çº¿ï¼ˆå¯é€‰åŒºé—´ï¼‰")
        if 'è¯„è®ºæ—¶é—´' in df.columns:
            df['è¯„è®ºæ—¶é—´'] = pd.to_datetime(df['è¯„è®ºæ—¶é—´'])
            min_date = df['è¯„è®ºæ—¶é—´'].min().date()
            max_date = df['è¯„è®ºæ—¶é—´'].max().date()
            col1, col2, col3 = st.columns([2,2,2])
            with col1:
                start_date = st.date_input("èµ·å§‹æ—¥æœŸ", min_value=min_date, max_value=max_date, value=min_date, key="start_date")
            with col2:
                end_date = st.date_input("ç»“æŸæ—¥æœŸ", min_value=min_date, max_value=max_date, value=max_date, key="end_date")
            with col3:
                freq = st.radio("èšåˆç²’åº¦", ["æŒ‰å¤©", "æŒ‰å°æ—¶"], horizontal=True, key="agg_freq")
            mask = (df['è¯„è®ºæ—¶é—´'].dt.date >= start_date) & (df['è¯„è®ºæ—¶é—´'].dt.date <= end_date)
            df_filtered = df.loc[mask].copy()
            if df_filtered.empty:
                st.warning("æ‰€é€‰åŒºé—´å†…æ— è¯„è®ºæ•°æ®ï¼")
            else:
                import altair as alt
                if freq == "æŒ‰å¤©":
                    df_filtered['æ—¥æœŸ'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.date
                    count_df = df_filtered.groupby('æ—¥æœŸ').size().reset_index(name='è¯„è®ºæ•°')
                    x = count_df['æ—¥æœŸ'].astype(str)
                else:
                    df_filtered['å°æ—¶'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.strftime('%Y-%m-%d %H:00')
                    count_df = df_filtered.groupby('å°æ—¶').size().reset_index(name='è¯„è®ºæ•°')
                    x = count_df['å°æ—¶']
                chart = alt.Chart(count_df).mark_line(point=True, color="#409EFF").encode(
                    x=alt.X(x.name, title="æ—¶é—´"),
                    y=alt.Y('è¯„è®ºæ•°', title="è¯„è®ºæ•°é‡"),
                    tooltip=[x.name, 'è¯„è®ºæ•°']
                ).properties(
                    width=700,
                    height=350
                ).interactive()
                st.altair_chart(chart, use_container_width=True)
    else:
        st.info("è¯·å…ˆçˆ¬å–è¯„è®ºæ•°æ®ã€‚")

def render_csv_section():
    """æœ¬åœ°CSVåˆ†æžåŒºå—"""
    import pandas as pd
    import os
    from analysis.word_cloud import load_stopwords, generate_wordcloud, generate_wordcloud_data
    from streamlit_echarts import st_echarts
    st.markdown("---")
    st.subheader("ðŸ“‚ æˆ–ç›´æŽ¥å±•ç¤ºæœ¬åœ° comments.csv æ•°æ®")
    if st.button("å±•ç¤ºCSVå›¾è¡¨", key="show_csv_btn"):
        csv_path = "comments.csv"
        if not os.path.exists(csv_path):
            st.error("å½“å‰ç›®å½•ä¸‹æœªæ‰¾åˆ° comments.csv æ–‡ä»¶ï¼")
        else:
            df_csv = pd.read_csv(csv_path)
            st.success(f"å·²åŠ è½½ comments.csvï¼Œå…± {len(df_csv)} æ¡è¯„è®º")
            st.dataframe(df_csv)
            # è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–æ›²çº¿
            if 'è¯„è®ºæ—¶é—´' in df_csv.columns:
                df_csv['è¯„è®ºæ—¶é—´'] = pd.to_datetime(df_csv['è¯„è®ºæ—¶é—´'], errors='coerce')
                min_date = df_csv['è¯„è®ºæ—¶é—´'].min().date()
                max_date = df_csv['è¯„è®ºæ—¶é—´'].max().date()
                col1, col2, col3 = st.columns([2,2,2])
                with col1:
                    start_date = st.date_input("èµ·å§‹æ—¥æœŸ", min_value=min_date, max_value=max_date, value=min_date, key="csv_start_date")
                with col2:
                    end_date = st.date_input("ç»“æŸæ—¥æœŸ", min_value=min_date, max_value=max_date, value=max_date, key="csv_end_date")
                with col3:
                    freq = st.radio("èšåˆç²’åº¦", ["æŒ‰å¤©", "æŒ‰æ˜ŸæœŸ"], horizontal=True, key="csv_agg_freq")
                mask = (df_csv['è¯„è®ºæ—¶é—´'].dt.date >= start_date) & (df_csv['è¯„è®ºæ—¶é—´'].dt.date <= end_date)
                df_filtered = df_csv.loc[mask].copy()
                if df_filtered.empty:
                    st.warning("æ‰€é€‰åŒºé—´å†…æ— è¯„è®ºæ•°æ®ï¼")
                else:
                    import altair as alt
                    if freq == "æŒ‰å¤©":
                        df_filtered['æ—¥æœŸ'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.date
                        count_df = df_filtered.groupby('æ—¥æœŸ').size().reset_index(name='è¯„è®ºæ•°')
                        x = count_df['æ—¥æœŸ'].astype(str)
                    else:  # æŒ‰æ˜ŸæœŸ
                        df_filtered['æ˜ŸæœŸ'] = df_filtered['è¯„è®ºæ—¶é—´'].dt.dayofweek
                        week_map = {0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'}
                        df_filtered['æ˜ŸæœŸ'] = df_filtered['æ˜ŸæœŸ'].map(week_map)
                        count_df = df_filtered.groupby('æ˜ŸæœŸ').size().reindex(['å‘¨ä¸€','å‘¨äºŒ','å‘¨ä¸‰','å‘¨å››','å‘¨äº”','å‘¨å…­','å‘¨æ—¥']).reset_index(name='è¯„è®ºæ•°').fillna(0)
                        x = count_df['æ˜ŸæœŸ']
                    chart = alt.Chart(count_df).mark_line(point=True, color="#13c2c2").encode(
                        x=alt.X(x.name, title="æ—¶é—´"),
                        y=alt.Y('è¯„è®ºæ•°', title="è¯„è®ºæ•°é‡"),
                        tooltip=[x.name, 'è¯„è®ºæ•°']
                    ).properties(
                        width=700,
                        height=350
                    ).interactive()
                    st.altair_chart(chart, use_container_width=True)
            # è¯äº‘ï¼ˆé™æ€/äº¤äº’ï¼‰
            if st.button("ç”Ÿæˆè¯äº‘ï¼ˆé™æ€ï¼‰", key="csv_wc_static"):
                if 'è¯„è®ºå†…å®¹' not in df_csv.columns:
                    st.error("CSVä¸­æ— è¯„è®ºå†…å®¹å­—æ®µï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df_csv['è¯„è®ºå†…å®¹'].astype(str))
                    stopwords = load_stopwords()
                    img = generate_wordcloud(text, stopwords)
                    if img is None:
                        st.warning("åˆ†è¯åŽæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        st.image(img, caption="è¯„è®ºè¯äº‘", use_container_width=True)
            if st.button("ç”Ÿæˆè¯äº‘ï¼ˆäº¤äº’ï¼‰", key="csv_wc_echarts"):
                if 'è¯„è®ºå†…å®¹' not in df_csv.columns:
                    st.error("CSVä¸­æ— è¯„è®ºå†…å®¹å­—æ®µï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                else:
                    text = ' '.join(df_csv['è¯„è®ºå†…å®¹'].astype(str))
                    stopwords = load_stopwords()
                    data = generate_wordcloud_data(text, stopwords)
                    if not data:
                        st.warning("åˆ†è¯åŽæ— æœ‰æ•ˆè¯è¯­ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
                    else:
                        option = {
                            "backgroundColor": "#f5f7fa",
                            "tooltip": {"show": True},
                            "series": [{
                                "type": 'wordCloud',
                                "shape": 'star',
                                "gridSize": 8,
                                "sizeRange": [20, 90],
                                "rotationRange": [-45, 90],
                                "rotationStep": 15,
                                "left": "center",
                                "top": "center",
                                "width": "100%",
                                "height": "100%",
                                "textStyle": {
                                    "fontFamily": "å¾®è½¯é›…é»‘",
                                    "fontWeight": "bold",
                                    "shadowColor": "#b7e3fa",
                                    "shadowBlur": 8,
                                    "color": {
                                        "type": "radial",
                                        "x": 0.5,
                                        "y": 0.5,
                                        "r": 0.8,
                                        "colorStops": [
                                            {"offset": 0, "color": "#91caff"},
                                            {"offset": 0.5, "color": "#f9e79f"},
                                            {"offset": 1, "color": "#ffb3b3"}
                                        ]
                                    }
                                },
                                "emphasis": {
                                    "focus": "self",
                                    "textStyle": {
                                        "shadowBlur": 16,
                                        "shadowColor": "#fff",
                                        "color": "#faad14"
                                    }
                                },
                                "drawOutOfBound": False,
                                "data": data
                            }]
                        }
                        st_echarts(option, height="600px")
